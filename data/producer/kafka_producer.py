# WSL í™˜ê²½ì—ì„œ, zookeeperë‘ kafka ì¼œë†“ê³  ëŒë ¤ì•¼í•¨!
'''
âœ” 5ë¶„ë§ˆë‹¤ ìë™ìœ¼ë¡œ ìƒˆ ë°ì´í„° í¬ë¡¤ë§
âœ” BeautifulSoupë¡œ ìµœì‹  ì°¨íŠ¸ íŒŒì‹±
âœ” Kafka Producer JSON ì§ë ¬í™” í›„ ì „ì†¡
âœ” Flinkì—ì„œ ì¤‘ë³µ ì œê±°í•  ìˆ˜ ìˆë„ë¡ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ë‚´ê¸°
'''
from kafka import KafkaProducer
import json
import time
import requests
from bs4 import BeautifulSoup
import pandas as pd
import schedule


GENRE_MAP = {
    "nb": "ë°œë¼ë“œ",
    "ndp": "ëŒ„ìŠ¤/íŒ",
    "nfa": "í¬í¬/ì–´ì¿ ìŠ¤í‹±",
    "nid": "ì•„ì´ëŒ",
    "nrh": "ë©/í™í•©",
    "nrs": "ì•Œì•¤ë¹„/ì†Œìš¸",
    "nkelec": "ì¼ë ‰íŠ¸ë¡œë‹‰",
    "nkrock": "ë½/ë©”íƒˆ",
    "nkjazz": "ì¬ì¦ˆ",
    "nindie": "ì¸ë””",
    "ntrot": "ì„±ì¸ê°€ìš”",
}

BASE_URL = "https://music.bugs.co.kr/newest/track/{genre_code}?page={page}"
HEADERS = {"User-Agent": "Mozilla/5.0"}


def get_lyrics(track_url):
    try:
        res = requests.get(track_url, headers=HEADERS, timeout=10)
        if res.status_code != 200:
            return ""
        soup = BeautifulSoup(res.text, "html.parser")
        xmp = soup.select_one("xmp")
        return xmp.text.strip() if xmp else ""
    except:
        return ""


def crawl_genre(genre_code, genre_name, max_page=2):

    titles = []
    artists = []
    albums = []
    lyrics_list = []

    for page in range(1, max_page + 1):
        url = BASE_URL.format(genre_code=genre_code, page=page)
        print(f"[{genre_name}] page={page} ìˆ˜ì§‘ ì¤‘ â†’ {url}")

        res = requests.get(url, headers=HEADERS, timeout=10)
        if res.status_code != 200:
            print(f"âŒ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {url}")
            continue

        soup = BeautifulSoup(res.text, "html.parser")

        for p in soup.select("p.title"):
            a = p.select_one("a[title]")
            if a:
                titles.append(a.get("title").strip())

        for p in soup.select("p.artist"):
            a = p.select_one("a[title]")
            if a:
                artists.append(a.get("title").strip())

        for a in soup.select("a.album[title]"):
            albums.append(a.get("title").strip())

        track_urls = [a.get("href") for a in soup.select("a.trackInfo[href]")]

        for t_url in track_urls:
            lyrics_list.append(get_lyrics(t_url))
            time.sleep(0.2)

        time.sleep(0.3)


    min_len = min(len(titles), len(artists), len(albums), len(lyrics_list))

    df = pd.DataFrame({
        "title": titles[:min_len],
        "artist": artists[:min_len],
        "album": albums[:min_len],
        "lyrics": lyrics_list[:min_len],
        "genre": [genre_name] * min_len
    })
    return df


# Kafka Producer ì„¤ì •
producer = KafkaProducer(
    bootstrap_servers="localhost:9092",
    value_serializer=lambda v: json.dumps(v, ensure_ascii=False).encode("utf-8"),
    acks="all"
)

TOPIC_NAME = 'music_topic'


def send_to_kafka(df):
    for idx, row in df.iterrows():
        
        if not row["lyrics"].strip():
            continue
        
        msg = {
            "title": row["title"],
            "artist": row["artist"],
            "album": row["album"],
            "lyrics": row["lyrics"],
            "genre": row["genre"],
        }

        producer.send(
            TOPIC_NAME,
            key=f"{row['title']}_{row['artist']}".encode('utf-8'),
            value=msg
        )

        print(f"[Kafka ì „ì†¡ ì™„ë£Œ] {row['title']} - {row['artist']}")
        time.sleep(0.1)

    producer.flush()
    print("\n=== ëª¨ë“  ë©”ì‹œì§€ Kafka ì „ì†¡ ì™„ë£Œ ===")


def job():
    print("\n===============================")
    print("ğŸ”¥ ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ & Kafka ì „ì†¡ ì‹œì‘")
    print("===============================\n")

    all_dfs = []
    for genre_code, genre_name in GENRE_MAP.items():
        df_genre = crawl_genre(genre_code, genre_name, max_page=2)
        all_dfs.append(df_genre)

    final_df = pd.concat(all_dfs, ignore_index=True)
    send_to_kafka(final_df)

    print("\n===== 1íšŒ ì‘ì—… ì™„ë£Œ, ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ëŒ€ê¸° =====\n")


schedule.every(5).minutes.do(job)

print("=== Kafka Producer ì‹¤í–‰ ì‹œì‘ (5ë¶„ë§ˆë‹¤ ìë™ ì‹¤í–‰) ===")

job()

while True:
    schedule.run_pending()
    time.sleep(1)
